{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6dfbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Lab | Imbalanced data\\n\\nWe will be using the `files_for_lab/customer_churn.csv` dataset to build a churn predictor.\\n\\n### Instructions\\n\\n1. Load the dataset and explore the variables.\\n2. We will try to predict variable `Churn` using a logistic regression on variables `tenure`, `SeniorCitizen`,`MonthlyCharges`.\\n3. Extract the target variable.\\n4. Extract the independent variables and scale them.\\n5. Build the logistic regression model.\\n6. Evaluate the model.\\n7. Even a simple model will give us more than 70% accuracy. Why?\\n8. **Synthetic Minority Oversampling TEchnique (SMOTE)\\n** is an over sampling technique based on nearest neighbors that adds new points between existing points. \\nApply `imblearn.over_sampling.SMOTE` to the dataset. Build and evaluate the logistic regression model. \\nIs it there any improvement?'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Lab | Imbalanced data\n",
    "\n",
    "We will be using the `files_for_lab/customer_churn.csv` dataset to build a churn predictor.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Load the dataset and explore the variables.\n",
    "2. We will try to predict variable `Churn` using a logistic regression on variables `tenure`, `SeniorCitizen`,`MonthlyCharges`.\n",
    "3. Extract the target variable.\n",
    "4. Extract the independent variables and scale them.\n",
    "5. Build the logistic regression model.\n",
    "6. Evaluate the model.\n",
    "7. Even a simple model will give us more than 70% accuracy. Why?\n",
    "8. **Synthetic Minority Oversampling TEchnique (SMOTE)\n",
    "** is an over sampling technique based on nearest neighbors that adds new points between existing points. \n",
    "Apply `imblearn.over_sampling.SMOTE` to the dataset. Build and evaluate the logistic regression model. \n",
    "Is it there any improvement?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb271de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "# To ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c8184b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenure</th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>monthlycharges</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5174</td>\n",
       "      <td>5174</td>\n",
       "      <td>5174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1869</td>\n",
       "      <td>1869</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tenure  seniorcitizen  monthlycharges\n",
       "churn                                       \n",
       "0        5174           5174            5174\n",
       "1        1869           1869            1869"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\filip\\OneDrive\\Desktop\\IRONHACK\\Labs\\Week5\\lab-imbalanced-data\\files_for_lab\\customer_churn.csv\")\n",
    "\n",
    "# Normalizing column names\n",
    "\n",
    "cols = []\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    cols.append(df.columns[i].lower().replace(' ','_'))\n",
    "    \n",
    "df.columns = cols\n",
    "\n",
    "# Checking data types\n",
    "df.dtypes\n",
    "\n",
    "\n",
    "# Checking for null values and droping\n",
    "df.isna().sum() #will drop, not significant\n",
    "\n",
    "\n",
    "# Converting 'churn'\n",
    "\n",
    "df.loc[df['churn'] == 'Yes', 'churn'] = 1\n",
    "df.loc[df['churn'] == 'No', 'churn'] = 0\n",
    "\n",
    "# Dropping columns\n",
    "df = df[['churn', 'tenure', 'seniorcitizen', 'monthlycharges']]\n",
    "\n",
    "#Converting target to numerical\n",
    "\n",
    "df['churn'] = pd.to_numeric(df['churn'])\n",
    "\n",
    "# Checking target count\n",
    "df.groupby('churn').count() #we have imbalanced data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1b4cd80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8055358410220014"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building a logistic regression model\n",
    "\n",
    "X = df.drop('churn',axis = 1)\n",
    "y = df['churn']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size = 0.2)\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e907f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = (Number of Correct Predictions) / (Total Number of Predictions)\n",
    "# Our accuracy is high but it only means we predicted 80% of the results but it doesn't provide provide a comprehensive assessment of the model's performance. \n",
    "#The evaluation metric depends on the specific goals, we should look at recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb16fc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.6911196911196911\n",
      "recall:  0.47989276139410186\n",
      "f1:  0.5664556962025317\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.87      1036\n",
      "           1       0.69      0.48      0.57       373\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.76      0.70      0.72      1409\n",
      "weighted avg       0.79      0.81      0.79      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "pred = LR.predict(X_test)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2c2e732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[956,  80],\n",
       "       [194, 179]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca40a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our recall is very low we(48%), missed 194 cases\n",
    "# Will use SMOTE to try to improve recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22c14152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tenure            231063.000000\n",
       "seniorcitizen       1179.000000\n",
       "monthlycharges    562821.518704\n",
       "churn               4138.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state =0,sampling_strategy=1)\n",
    "X_train_SMOTE,y_train_SMOTE = sm.fit_resample(X_train,y_train)\n",
    "\n",
    "train_smote = pd.concat([X_train_SMOTE,y_train_SMOTE], axis = 1)\n",
    "train_smote\n",
    "train_smote.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf931591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.5126811594202898\n",
      "recall:  0.7587131367292225\n",
      "f1:  0.6118918918918917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81      1036\n",
      "           1       0.51      0.76      0.61       373\n",
      "\n",
      "    accuracy                           0.75      1409\n",
      "   macro avg       0.70      0.75      0.71      1409\n",
      "weighted avg       0.79      0.75      0.76      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "pred = LR.predict(X_test)\n",
    "\n",
    "print(\"precision: \",precision_score(y_test,pred))\n",
    "print(\"recall: \",recall_score(y_test,pred))\n",
    "print(\"f1: \",f1_score(y_test,pred))\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b40e2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[767, 269],\n",
       "       [ 90, 283]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e764dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The recall improved to 75% and we missed 90 case instead of 194"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
